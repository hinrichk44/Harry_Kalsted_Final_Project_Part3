{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset I used for my final project is a documentation of property sales in Brooklyn from 2003-2017 that I found on Kaggle. The target variable I tried to predict in this dataset was the sale price of the properties. In Part 1 I wanted an accuracy score of 80%, after many attempts I did not come close to that mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in of the dataset\n",
    "\n",
    "brooklyn = pd.read_csv(\"brooklyn_sales_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>borough</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>building_class_category</th>\n",
       "      <th>tax_class</th>\n",
       "      <th>block</th>\n",
       "      <th>lot</th>\n",
       "      <th>building_class</th>\n",
       "      <th>address</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>...</th>\n",
       "      <th>XCoord</th>\n",
       "      <th>YCoord</th>\n",
       "      <th>ZoneMap</th>\n",
       "      <th>ZMCode</th>\n",
       "      <th>Sanborn</th>\n",
       "      <th>TaxMap</th>\n",
       "      <th>EDesigNum</th>\n",
       "      <th>Version</th>\n",
       "      <th>SHAPE_Leng</th>\n",
       "      <th>SHAPE_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DOWNTOWN-METROTECH</td>\n",
       "      <td>28  COMMERCIAL CONDOS</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>1001</td>\n",
       "      <td>R5</td>\n",
       "      <td>330 JAY STREET</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>DOWNTOWN-FULTON FERRY</td>\n",
       "      <td>29  COMMERCIAL GARAGES</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>G7</td>\n",
       "      <td>85 JAY STREET</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>988208.0</td>\n",
       "      <td>195011.0</td>\n",
       "      <td>12d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302 016</td>\n",
       "      <td>30101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17V1.1</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>140132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>BROOKLYN HEIGHTS</td>\n",
       "      <td>21  OFFICE BUILDINGS</td>\n",
       "      <td>4</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>O6</td>\n",
       "      <td>29 COLUMBIA HEIGHTS</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>985952.0</td>\n",
       "      <td>195007.0</td>\n",
       "      <td>12d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302 004</td>\n",
       "      <td>30106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17V1.1</td>\n",
       "      <td>891.0</td>\n",
       "      <td>34656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>MILL BASIN</td>\n",
       "      <td>22  STORE BUILDINGS</td>\n",
       "      <td>4</td>\n",
       "      <td>8470</td>\n",
       "      <td>55</td>\n",
       "      <td>K6</td>\n",
       "      <td>5120 AVENUE U</td>\n",
       "      <td>11234</td>\n",
       "      <td>...</td>\n",
       "      <td>1006597.0</td>\n",
       "      <td>161424.0</td>\n",
       "      <td>23b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>319 077</td>\n",
       "      <td>32502.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17V1.1</td>\n",
       "      <td>3730.0</td>\n",
       "      <td>797555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>BROOKLYN HEIGHTS</td>\n",
       "      <td>26 OTHER HOTELS</td>\n",
       "      <td>4</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>H8</td>\n",
       "      <td>21 CLARK STREET</td>\n",
       "      <td>11201</td>\n",
       "      <td>...</td>\n",
       "      <td>985622.0</td>\n",
       "      <td>193713.0</td>\n",
       "      <td>12d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302 014</td>\n",
       "      <td>30106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17V1.1</td>\n",
       "      <td>621.0</td>\n",
       "      <td>21360.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  borough           neighborhood building_class_category  \\\n",
       "0           1        3     DOWNTOWN-METROTECH   28  COMMERCIAL CONDOS   \n",
       "1           2        3  DOWNTOWN-FULTON FERRY  29  COMMERCIAL GARAGES   \n",
       "2           3        3       BROOKLYN HEIGHTS    21  OFFICE BUILDINGS   \n",
       "3           4        3             MILL BASIN     22  STORE BUILDINGS   \n",
       "4           5        3       BROOKLYN HEIGHTS         26 OTHER HOTELS   \n",
       "\n",
       "  tax_class  block   lot building_class              address  zip_code  \\\n",
       "0         4    140  1001             R5       330 JAY STREET     11201   \n",
       "1         4     54     1             G7        85 JAY STREET     11201   \n",
       "2         4    204     1             O6  29 COLUMBIA HEIGHTS     11201   \n",
       "3         4   8470    55             K6        5120 AVENUE U     11234   \n",
       "4         4    230     1             H8      21 CLARK STREET     11201   \n",
       "\n",
       "      ...         XCoord    YCoord  ZoneMap  ZMCode  Sanborn   TaxMap  \\\n",
       "0     ...            NaN       NaN      NaN     NaN      NaN      NaN   \n",
       "1     ...       988208.0  195011.0      12d     NaN  302 016  30101.0   \n",
       "2     ...       985952.0  195007.0      12d     NaN  302 004  30106.0   \n",
       "3     ...      1006597.0  161424.0      23b     NaN  319 077  32502.0   \n",
       "4     ...       985622.0  193713.0      12d     NaN  302 014  30106.0   \n",
       "\n",
       "   EDesigNum Version  SHAPE_Leng  SHAPE_Area  \n",
       "0        NaN     NaN         NaN         NaN  \n",
       "1        NaN  17V1.1      1560.0    140132.0  \n",
       "2        NaN  17V1.1       891.0     34656.0  \n",
       "3        NaN  17V1.1      3730.0    797555.0  \n",
       "4        NaN  17V1.1       621.0     21360.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A brief look at the dataset\n",
    "\n",
    "brooklyn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During Part 2 of this project I realized my dataset had repetitive columns, columns that were mostly null values, columns that had a lot of values equal to zero when they shouldn't have been, and columns that were obsolete like \"borough.\" In order to get the most accurate model possible, I had to do a lot of cleaning before the dataset could be properly analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn.drop(brooklyn.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn.drop(['borough','address','building_class','ZipCode','Address','BldgClass','YearAlter1','YearAlter2',\n",
    "                          'BoroCode','ZMCode','EDesigNum','tax_class','OwnerType','OwnerName','YearBuilt','SanitBoro','SanitSub',\n",
    "                          'Version', 'UnitsTotal','block','lot','SHAPE_Leng','SHAPE_Area','ZoneMap','XCoord','YCoord','CD','CT2010',\n",
    "                         'CB2010','year_of_sale','Council','FireComp','year_built','HealthCent','HealthArea','SanitDistr','ZoneDist1',\n",
    "                         'SplitZone','LandUse','Easements','ComArea','ResArea','AreaSource',\n",
    "                         'NumBldgs','zip_code','UnitsRes','LotDepth','BldgDepth','ProxCode',\n",
    "                         'IrrLotCode','LotType','BsmtCode','AssessLand','ExemptLand','ExemptTot','BuiltFAR','ResidFAR','CommFAR','FacilFAR',\n",
    "                          'BBL','Tract2010','Sanborn','TaxMap','building_class_at_sale','neighborhood','building_class_category'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disregarding null and non-sensical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.sale_price >= 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.gross_sqft >= 100.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.AssessTot >= 500.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.land_sqft != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.total_units != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.commercial_units != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.residential_units != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.LotArea != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.BldgArea != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.NumFloors != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.LotFront != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.BldgFront != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.tax_class_at_sale != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn[brooklyn.PolicePrct != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of dataset post-cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11353, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brooklyn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "residential_units      int64\n",
       "commercial_units       int64\n",
       "total_units            int64\n",
       "land_sqft            float64\n",
       "gross_sqft           float64\n",
       "tax_class_at_sale      int64\n",
       "sale_price             int64\n",
       "SchoolDist           float64\n",
       "PolicePrct           float64\n",
       "LotArea              float64\n",
       "BldgArea             float64\n",
       "NumFloors            float64\n",
       "LotFront             float64\n",
       "BldgFront            float64\n",
       "AssessTot            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brooklyn.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting datatypes from numerical into categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn = brooklyn.astype({'tax_class_at_sale':str, 'SchoolDist':str, 'PolicePrct': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaned Linear Regression Model Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all of the cleaning, here was one of the best models I came up with. I only used numerical values because the addition of categorical values did not actually change the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "brooklyn_numeric = brooklyn.select_dtypes(['int64', 'float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the variables between X and y\n",
    "\n",
    "X = brooklyn_numeric.drop('sale_price', axis='columns')\n",
    "y = brooklyn_numeric.loc[:, 'sale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a training set and a test set\n",
    "#test_size = .3 means 30% of the data is set aside for the test set. 70% of the data is used for the training set\n",
    "#You could also use train_size if you wish\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up a linear regression model using the training set\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39868403947888487\n",
      "0.129957525673436\n"
     ]
    }
   ],
   "source": [
    "#Scoring the model on the training set and test set.\n",
    "#These are the R-squared values for the training set and test set. \n",
    "\n",
    "print(lr.score(X_train, y_train))\n",
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model clearly suffered from overfitting. You can tell because of the large discrepancy in R-squared values from the training set to the test set. Because the test set performed worse than the training set, there is evidence of high variance in my model. The only good news is that at least my model performed better than a null model, so it has some predictive value, even if it's very little."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next best model I came up with was a random forest regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the variables between X and y\n",
    "\n",
    "X2 = brooklyn_numeric.drop('sale_price', axis='columns')\n",
    "y2 = brooklyn_numeric.loc[:, 'sale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a training set and a test set\n",
    "#test_size = .3 means 30% of the data is set aside for the test set. 70% of the data is used for the training set\n",
    "#You could also use train_size if you wish\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = .3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8812324475685837\n",
      "0.4265660936875144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=200)\n",
    "rfr.fit(X2_train, y2_train)\n",
    "print(rfr.score(X2_train, y2_train))\n",
    "print(rfr.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance it may seem like I came up with a strongly predictive model since the R-squared for the training set showed that it captured 88% of the variance in the model. However, once you look at the test set, you realize my model once again has a severe overfitting problem. The test set captured less than half of the variance as the training set. That is not a good model to rely on. The random forest regression did however have better predictive scores in the training and test sets compared to the standard linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the best way to reduce the variance in your model is to collect more data, that was not an option I could do here. Instead, the next best thing I could do was make the model less complex. When I did a correlation matrix between all the variables in my model, I noticed some feature variables had correlations of 90% or more between them, which to me signified the dreaded collinearity problem. I dropped the variables I believed suffered from collinearity in order to make my model less complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_brooklyn = brooklyn_numeric.drop(['residential_units','total_units','land_sqft','LotArea','gross_sqft'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Better Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a second round of cleaning I ran a standard linear regression model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the variables between X and y\n",
    "\n",
    "X3 = new_brooklyn.drop('sale_price', axis='columns')\n",
    "y3 = new_brooklyn.loc[:, 'sale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a training set and a test set\n",
    "#test_size = .3 means 30% of the data is set aside for the test set. 70% of the data is used for the training set\n",
    "#You could also use train_size if you wish\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size = .3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up a linear regression model using the training set\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2882759971197526\n",
      "0.18442172375582888\n"
     ]
    }
   ],
   "source": [
    "#Scoring the model on the training set and test set.\n",
    "#These are the R-squared values for the training set and test set. \n",
    "\n",
    "print(lr.score(X3_train, y3_train))\n",
    "print(lr.score(X3_test, y3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although my new model still wasn't very predictive, I believe it was much improved from the first linear regression model. For one, the test score R-squared value increased. For another, the discrepancy in R-squared values from the training set to test was much less than the first try. I still have a high variance problem, but I was happy that it was reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to see if my cleaned up model would lead to a better predictive result through random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the variables between X and y\n",
    "\n",
    "X4 = new_brooklyn.drop('sale_price', axis='columns')\n",
    "y4 = new_brooklyn.loc[:, 'sale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a training set and a test set\n",
    "#test_size = .3 means 30% of the data is set aside for the test set. 70% of the data is used for the training set\n",
    "#You could also use train_size if you wish\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size = .3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660278199645169\n",
      "0.408682955945329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=200)\n",
    "rfr.fit(X4_train, y4_train)\n",
    "print(rfr.score(X4_train, y4_train))\n",
    "print(rfr.score(X4_test, y4_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result really had no discernable difference from the first random forest regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part 2 I tried several alterations of the data like log and polynomial transformations and those did not improve the predictive capabilities of my model at all. The biggest problem I continued to have besides low R-squared values was the high variance. I tried to address the overfitting problem by using Ridge Regression and XGB Boost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = new_brooklyn.drop('sale_price', axis='columns')\n",
    "y5 = new_brooklyn.loc[:, 'sale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalstedh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\kalstedh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "ridge = Ridge(alpha=100)\n",
    "X5_scaled = scaler.fit_transform(X5)\n",
    "ridge.fit(X5_scaled, y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2723957427753054"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(X5_scaled, y5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will admit I am not 100% sure I used ridge regression correctly. The code seemed semi-confusing. In the case that I did use it correctly, a score of .27 is better than any test score in the standard linear regression models I ran."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6 = new_brooklyn.drop('sale_price', axis='columns')\n",
    "y6 = new_brooklyn.loc[:, 'sale_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_reg = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(X6, y6, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalstedh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg.fit(X6_train, y6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815403235116115\n",
      "0.33989316192020724\n"
     ]
    }
   ],
   "source": [
    "print(xgb_reg.score(X6_train, y6_train))\n",
    "print(xgb_reg.score(X6_test, y6_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGB Boost model looked like it suffered the same fate as the random forest regressor model. Both had high R-squared values on the training set, but the R-squared values on the test sets were so much smaller that it's not worth touting the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After many different variations, my modeling of the sale price of Brooklyn properties did not end up being very predictive, and also suffered from overfitting and high variance. If I had another week, I would try to learn how to rank feature variables. I know we covered it, but I don't know it well enough to use it. Although the random forest models had higher R-squared values than the linear regression models, I still feel more comfortable claiming the linear regression models are more predictive because there was much less variance in those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
